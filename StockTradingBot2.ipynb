{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZCaYlrueaqPeOK7Y9y1VT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gtyellow/stockbot/blob/main/StockTradingBot2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kCuPXrLTl1iR"
      },
      "outputs": [],
      "source": [
        "#!pip install yfinance sec-api vaderSentiment scikit-learn xgboost tensorflow newsapi-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install finnhub-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4v9pXcPockJ",
        "outputId": "3895239d-aed0-4fe8-8dc2-f3b23c41eaac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting finnhub-python\n",
            "  Downloading finnhub_python-2.4.20-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from finnhub-python) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->finnhub-python) (2024.8.30)\n",
            "Downloading finnhub_python-2.4.20-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: finnhub-python\n",
            "Successfully installed finnhub-python-2.4.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from sec_api import QueryApi\n",
        "import finnhub\n",
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "h3vb7yIdmDfl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# SEC API initialization\n",
        "sec_api = QueryApi(api_key='680a77dac860076b7302bbf2789c1b66787a98d94189fb328954d42fd5806439')\n",
        "finnhub_client = finnhub.Client(api_key=\"crku8ghr01qhc7mjec30crku8ghr01qhc7mjec3g\")\n",
        "\n",
        "# Stock symbols\n",
        "stocks = ['W', 'PTON', 'SHC', 'CVNA', 'ARWR', 'EVA', 'CHGG', 'CALX', 'LIFW', 'ELF',\n",
        "          'HP', 'FRO', 'CEIX', 'SMCI', 'ANET', 'LSCC', 'TTD', 'FSLR',\n",
        "          'PSTG', 'GNRC', 'NUS', 'TDC', 'IOT']"
      ],
      "metadata": {
        "id": "IsHvrKHumF_g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch historical price data\n",
        "def get_stock_data(symbols, start=\"2023-01-01\", end=\"2023-12-31\"):\n",
        "    all_data = {}\n",
        "    for symbol in symbols:\n",
        "        df = yf.download(symbol, start=start, end=end)\n",
        "        all_data[symbol] = df\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "jq9sqGVxmNWO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch 10-K, 10-Q filings from SEC\n",
        "def fetch_financial_statements(stock):\n",
        "    query = {\n",
        "        \"query\": { \"query_string\": { \"query\": f\"ticker:{stock} AND formType:(10-K OR 10-Q)\" } },\n",
        "        \"from\": \"2023-01-01\",\n",
        "        \"to\": \"2023-12-31\",\n",
        "        \"sort\": [{\"filedAt\": {\"order\": \"desc\"}}]\n",
        "    }\n",
        "    filings = sec_api.get_filings(query)\n",
        "    return filings"
      ],
      "metadata": {
        "id": "SA0RjSJ6mRZI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# News sentiment analysis\n",
        "def get_news_sentiment(symbol, start_date, end_date):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    try:\n",
        "        news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching news for {symbol}: {e}\")\n",
        "        return 0\n",
        "\n",
        "    sentiment_scores = []\n",
        "\n",
        "    for article in news:\n",
        "        text = article.get('headline', '') + ' ' + article.get('summary', '')\n",
        "        if text:\n",
        "            sentiment = analyzer.polarity_scores(text)\n",
        "            sentiment_scores.append(sentiment['compound'])\n",
        "\n",
        "    if sentiment_scores:\n",
        "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
        "    else:\n",
        "        avg_sentiment = 0\n",
        "\n",
        "    return avg_sentiment\n"
      ],
      "metadata": {
        "id": "8YT3DfCamX59"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_financial_metrics(filings):\n",
        "    # This is a placeholder function. Extracting financial metrics from filings requires parsing the documents.\n",
        "    # For simplicity, we'll return dummy data. In a real scenario, you would parse the filings to extract actual data.\n",
        "    metrics = {\n",
        "        'revenue': np.random.uniform(100, 1000),  # Placeholder for revenue\n",
        "        'net_income': np.random.uniform(-100, 500),  # Placeholder for net income\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Fij7D4LHpzfB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_training_data(stock_data, financial_data, news_sentiment):\n",
        "    all_features = []\n",
        "    all_targets = []\n",
        "\n",
        "    for stock, data in stock_data.items():\n",
        "        prices = data['Close'].pct_change().fillna(0)  # Daily percentage change\n",
        "        target = np.sign(prices.values[1:])  # Skip the first NaN value\n",
        "\n",
        "        # Financial metrics\n",
        "        financial_metrics = extract_financial_metrics(financial_data[stock])\n",
        "\n",
        "        # Repeat financial metrics to match the length of the price data\n",
        "        revenue = np.full(len(target), financial_metrics['revenue'])\n",
        "        net_income = np.full(len(target), financial_metrics['net_income'])\n",
        "\n",
        "        # News sentiment\n",
        "        sentiment = np.full(len(target), news_sentiment.get(stock, 0))\n",
        "\n",
        "        # Features: [Revenue, Net Income, Sentiment]\n",
        "        features = np.column_stack((revenue, net_income, sentiment))\n",
        "\n",
        "        all_features.append(features)\n",
        "        all_targets.append(target)\n",
        "\n",
        "    X = np.vstack(all_features)\n",
        "    y = np.hstack(all_targets)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "D764DZIIp9HA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "_E_oEjLRqNV-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data\n",
        "stock_data = get_stock_data(stocks)\n",
        "financial_data = {stock: fetch_financial_statements(stock) for stock in stocks}\n",
        "news_sentiment = {stock: get_news_sentiment(stock, \"2023-01-01\", \"2023-12-31\") for stock in stocks}\n",
        "\n",
        "# Prepare training data\n",
        "X, y = prepare_training_data(stock_data, financial_data, news_sentiment)\n",
        "\n",
        "# Remove any potential NaN or infinite values\n",
        "X = np.nan_to_num(X)\n",
        "y = np.nan_to_num(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hd61ymvp_SF",
        "outputId": "140f0670-cbf7-436e-ad16-24e35119f3d5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Map y labels to [0, 1, 2]\n",
        "y_train_mapped = np.where(y_train == -1, 0, y_train + 1)\n",
        "y_test_mapped = np.where(y_test == -1, 0, y_test + 1)\n",
        "\n",
        "# Now y_train_mapped and y_test_mapped will be in the range [0, 1, 2]\n"
      ],
      "metadata": {
        "id": "XNOWxMEtqObC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_mapped)\n",
        "\n",
        "# Evaluate the model using remapped labels\n",
        "y_pred_mapped = model.predict(X_test)\n",
        "\n",
        "# Reverse the mapping to [-1, 0, 1] for evaluation\n",
        "y_pred = np.where(y_pred_mapped == 0, -1, y_pred_mapped - 1)\n",
        "\n",
        "# Check accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgrMc2_RsJjg",
        "outputId": "633e5dd5-9d9a-4610-b16e-7bf459cece11"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 52.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [20:33:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define backtest stocks\n",
        "backtest_stocks = ['ZS', 'SNOW', 'CRWD', 'MDB', 'OKTA']  # Example stocks\n",
        "\n",
        "# Fetch backtest stock data\n",
        "backtest_stock_data = get_stock_data(backtest_stocks)\n",
        "backtest_financial_data = {stock: fetch_financial_statements(stock) for stock in backtest_stocks}\n",
        "backtest_news_sentiment = {stock: get_news_sentiment(stock, \"2023-01-01\", \"2023-12-31\") for stock in backtest_stocks}\n",
        "\n",
        "# Prepare backtest data\n",
        "X_backtest, y_backtest = prepare_training_data(backtest_stock_data, backtest_financial_data, backtest_news_sentiment)\n",
        "X_backtest_scaled = scaler.transform(X_backtest)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_backtest_pred = model.predict(X_backtest_scaled)\n",
        "backtest_accuracy = accuracy_score(y_backtest, y_backtest_pred)\n",
        "\n",
        "print(f\"Backtest accuracy: {backtest_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RlMieeWrCJB",
        "outputId": "9acbbd09-5233-4d02-de3d-897c5f34a33e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest accuracy: 0.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51KTi_iLqFGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}